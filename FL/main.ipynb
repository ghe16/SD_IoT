{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q flwr[simulation] flwr-datasets[vision] torch torchvision matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gustavo\\Downloads\\prueba2\\SD_IoT\\FL\\.pruebaVS\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-08-05 20:00:18,445\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu\n",
      "Flower 1.10.0 / PyTorch 2.3.1+cpu\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import List, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from datasets.utils.logging import disable_progress_bar\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import flwr\n",
    "from flwr.client import Client, ClientApp, NumPyClient\n",
    "from flwr.common import Metrics, Context\n",
    "from flwr.server import ServerApp, ServerConfig, ServerAppComponents\n",
    "from flwr.server.strategy import FedAvg\n",
    "from flwr.simulation import run_simulation\n",
    "from flwr_datasets import FederatedDataset\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")  # Try \"cuda\" to train on GPU\n",
    "print(f\"Training on {DEVICE}\")\n",
    "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")\n",
    "disable_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLIENTS = 10\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "def load_datasets(partition_id: int):\n",
    "    fds = FederatedDataset(dataset=\"cifar10\", partitioners={\"train\": NUM_CLIENTS})\n",
    "    partition = fds.load_partition(partition_id)\n",
    "    # Divide data on each node: 80% train, 20% test\n",
    "    partition_train_test = partition.train_test_split(test_size=0.2, seed=42)\n",
    "    pytorch_transforms = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "    )\n",
    "\n",
    "    def apply_transforms(batch):\n",
    "        # Instead of passing transforms to CIFAR10(..., transform=transform)\n",
    "        # we will use this function to dataset.with_transform(apply_transforms)\n",
    "        # The transforms object is exactly the same\n",
    "        batch[\"img\"] = [pytorch_transforms(img) for img in batch[\"img\"]]\n",
    "        return batch\n",
    "\n",
    "    # Create train/val for each partition and wrap it into DataLoader\n",
    "    partition_train_test = partition_train_test.with_transform(apply_transforms)\n",
    "    trainloader = DataLoader(\n",
    "        partition_train_test[\"train\"], batch_size=BATCH_SIZE, shuffle=True\n",
    "    )\n",
    "    valloader = DataLoader(partition_train_test[\"test\"], batch_size=BATCH_SIZE)\n",
    "    testset = fds.load_split(\"test\").with_transform(apply_transforms)\n",
    "    testloader = DataLoader(testset, batch_size=BATCH_SIZE)\n",
    "    return trainloader, valloader, testloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estamos usando la librería datasets y las utilidades de pytorch para poder crear un dataset que podamos usar de manera disrtibuida. En este caso se usa el dataset CIFAR 10. Más información del dataset,  https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html \n",
    "Variables:\n",
    "* NUM_CLIENTS es el número de nodos de la red federada. En este caso, 10. \n",
    "* BATCH_SIZE es el tamaño promedio de los \"trozos de datos\" que emplearemos para el entrenamiento. \n",
    "* Como resultado teneos una parte del dataset para entrenamiento del modelo, una para pruebas y otra para la validacion del modelo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos ahora a graficar algunas imagenes del dataset. Para esto nos apoyamos de la librería matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader, _, _ = load_datasets(partition_id=0)\n",
    "batch = next(iter(trainloader))\n",
    "images, labels = batch[\"img\"], batch[\"label\"]\n",
    "\n",
    "# Reshape and convert images to a NumPy array\n",
    "# matplotlib requires images with the shape (height, width, 3)\n",
    "images = images.permute(0, 2, 3, 1).numpy()\n",
    "\n",
    "# Denormalize\n",
    "images = images / 2 + 0.5\n",
    "\n",
    "# Create a figure and a grid of subplots\n",
    "fig, axs = plt.subplots(4, 8, figsize=(12, 6))\n",
    "\n",
    "# Loop over the images and plot them\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    ax.imshow(images[i])\n",
    "    ax.set_title(trainloader.dataset.features[\"label\"].int2str([labels[i]])[0])\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "# Show the plot\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, vamos a crear un modelo para el entrenamiento. Para esto, prinicplamente usaremos la librería torch. Esta librería permite el entrenamiento de algoritmos de IA, expresando el modelo en \"tensores\". Son valores que se van actualizando en el tiempo, y que pueden ser distribuidos en el hardware que los ejecuta, normalmente una GPU.  El modelo se define como una clase que instanciaremos varias veces (una por nodo aunque sea la misma). El modelo que veremos a continuación es muy sencillo y contiene dos capas convolucionales, dos capas totalmente conectadas (o fully connected fc) y capas de pooling que reducen normalmente el tamaño del mapa de características.  La función Relu es una función de activación. Lo que devuelve esta función es un mapa de características expresado en tensores.  Más información en los componentes y tipos de capas se puede encontrar aquí: https://pytorch.org/tutorials/recipes/recipes/defining_a_neural_network.html   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, vamos a crear las funciones típicas de entrenamiento de IA, que son la de entrenamiento sobre los datos de training, y la de evvaluación sobre los datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, trainloader, epochs: int, verbose=False):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters())\n",
    "    net.train()\n",
    "    for epoch in range(epochs):\n",
    "        correct, total, epoch_loss = 0, 0, 0.0\n",
    "        for batch in trainloader:\n",
    "            images, labels = batch[\"img\"].to(DEVICE), batch[\"label\"].to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Metrics\n",
    "            epoch_loss += loss\n",
    "            total += labels.size(0)\n",
    "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
    "        epoch_loss /= len(trainloader.dataset)\n",
    "        epoch_acc = correct / total\n",
    "        if verbose:\n",
    "            print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
    "\n",
    "\n",
    "def test(net, testloader):\n",
    "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in testloader:\n",
    "            images, labels = batch[\"img\"].to(DEVICE), batch[\"label\"].to(DEVICE)\n",
    "            outputs = net(images)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    loss /= len(testloader.dataset)\n",
    "    accuracy = correct / total\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Entrenamiento centralizado. \n",
    "\n",
    "Ya tenemos el modelo, los datos y las funciones de entrenamitno.. Pues, vamos a entrenar. El código de abajo realiza este proceso para uno de los nodos \"partition_id\"  En este caso, el número 0  que simularía el nodo 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: validation loss 0.058892894864082335, accuracy 0.344\n",
      "Epoch 2: validation loss 0.05364039552211761, accuracy 0.403\n",
      "Epoch 3: validation loss 0.05173851764202118, accuracy 0.419\n",
      "Epoch 4: validation loss 0.04914828205108643, accuracy 0.463\n",
      "Epoch 5: validation loss 0.049026955485343936, accuracy 0.453\n",
      "Final test set performance:\n",
      "\tloss 0.049915652310848234\n",
      "\taccuracy 0.4194\n"
     ]
    }
   ],
   "source": [
    "trainloader, valloader, testloader = load_datasets(partition_id=0)\n",
    "net = Net().to(DEVICE)\n",
    "\n",
    "for epoch in range(5):\n",
    "    train(net, trainloader, 1)\n",
    "    loss, accuracy = test(net, valloader)\n",
    "    print(f\"Epoch {epoch+1}: validation loss {loss}, accuracy {accuracy}\")\n",
    "\n",
    "loss, accuracy = test(net, testloader)\n",
    "print(f\"Final test set performance:\\n\\tloss {loss}\\n\\taccuracy {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos observar, si todo va bien, deberíammos haber tenido 5 épocas de entramiento. Una época en IA es una barrida de entrenamiento de un modelo sobre todos los datos de un dataset. Como vemos, la función **train** toma como parametros de entrada la red neuronal (modelo que describimos arriba)  y los datos para entrenamiento. La función **test** evalua que tan bien lo está haciendo mi modelo...  La función se imprime para cada época y para el final de las iteraciones.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si has llegado hasta aquí, en cierto modo has conseguido realizar una operción de entrenamiento de una red neuronal... Enhorabuena.... Aunque, podemos ir más allá. a por ello..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Entrenamiento Federado\n",
    "Ahora, vamos a simular un entorno diferente. Imaginaros que realmente tenemos 10 nodos diferentes, que cada uno tiene parte de nuestro dataset, y que queremos se entrene de manera distribuida. ¿Como lo hacemos?  Con Federated Learning. Existen varias distribuciones de FL. La idea original viene de google y está descrito en este artículo (https://arxiv.org/pdf/1602.05629). Gracias a FL, google mejora la experiencia de sus herramientas de AI, sin \"conocer\" nuestros datos.   Esa implementación está realizada en Golang, el lenguaie de programación de google. No queremos entrar en otro lenguaje más, así que optaremos por la implementación usando Flower, que se ha impuesto como la librería más robusta para aplicaciones federadas. Más información de Flower:   https://flower.ai/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actualizando los parametros de los modelos. \n",
    "Si ahora tenemos 10 nodos, por lógica, tenemos 10 versiones del modelo de la red neuronal. Cada una depende de los datos en lso que se entrena. Imaginaros la situación: 10 hospitales tienen datos clinicos de pacientes. Pero estos datos son propios del hospital ( y de los pacientes) y los hospitales no se arriesgan a exponer sus datos y que haya un problema por exponer la ifnormación de sus pacientes. Para esto, el Federated Learning, permite que cada hospital actualice los datos del modelo, entrenandolo con sus datos, y actualizando los pesos. Lo único que se intercambia entre los nodos son los pesos del modelo. Así los datos no abandonan el lugar de origen (por ejemplo el hospital), los hospitales reducen el riesgo de exponer información sensible, peeeeero, la sociedad podría beneficiarse de estos modelos de IA que pueden salvar vidas.    Por ello, vamos a definir un par de funciones que actualizan los pesos de lso nodos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameters(net, parameters: List[np.ndarray]):\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "\n",
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estas 2 funciones obtienen los valores de los modelos de IA en valores numéricos estandar (numpy) o valores de tesnores cuando se actualizan los pesos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definir un cliente para cada nodo\n",
    "Flower trabaja tomando un conjunto de nodos como cliente y otro como servidor (imaginad el servidor es el nodo que agrupa todos los valores y los agrega para tener un entrenamiento distribuido con un modelo resultante que se pueda ejecutar en cualquier sitio). En nuestro caso, todo se ejecuta en una misma máquina, con lo cual efectuaremos una simulación. Tened en cuenta que los algoritmos de IA consumen muchos recursos, y tener varias instancias ejecutandose al mismo tiempo puede rapidamente colapsar nuestors equipos. Para facilitar esta tarea, la herramienta de simulación de Flower permite que se haga una planificación temporal de los nodos, y que no se ejecuten todos al tiempo, conservando los recursos de nuestra máquina. A continacón vamos a definir como se vería la apliccación de un cliente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerClient(NumPyClient):\n",
    "    def __init__(self, net, trainloader, valloader):\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        set_parameters(self.net, parameters)\n",
    "        train(self.net, self.trainloader, epochs=1)\n",
    "        return get_parameters(self.net), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se observa, el cliente, tiene cuatro funciones principales:\n",
    "* La de inicialización (**__init__**), que permite o \"simula\" la recogida de los datos locales (imaginaros los datos de cada hospital)\n",
    "* **get_parameters**: función definida anteriormente, que permite recoger (del servidor) la versión más actual de los pesos de mi modelo de IA. \n",
    "* **fit**: Esta función coge los valores más actualizados de los pesos, los asigna al modelo (local) y se pone a entyrenar con los datos de ese nodo. Deolverá por un lado los valores de los pesos del modelo más actualizados, y por otro lado la longitud del datasset con el cual ha entrenado Esto es útil para que la agregación no quede desbalanceada. No es lo mismo entrenar un modelo con 100 muestras que con  1000000000. \n",
    "*  **evaluate**: esta función simpelemnten evalua las métricas para el entrenamiento que acaba de realizar.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora lo que haremos es crear una función cliente que llame tantas veces a la clase de FlowerCLient como sea necesario (por ejemplo, 10 veces para cada nodo en una época):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_fn(context: Context) -> Client:\n",
    "    \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
    "\n",
    "    # Load model\n",
    "    net = Net().to(DEVICE)\n",
    "\n",
    "    # Load data (CIFAR-10)\n",
    "    # Note: each client gets a different trainloader/valloader, so each client\n",
    "    # will train and evaluate on their own unique data partition\n",
    "    # Read the node_config to fetch data partition associated to this node\n",
    "    partition_id = context.node_config[\"partition-id\"]\n",
    "    trainloader, valloader, _ = load_datasets(partition_id=partition_id)\n",
    "\n",
    "    # Create a single Flower client representing a single organization\n",
    "    # FlowerClient is a subclass of NumPyClient, so we need to call .to_client()\n",
    "    # to convert it to a subclass of `flwr.client.Client`\n",
    "    return FlowerClient(net, trainloader, valloader).to_client()\n",
    "\n",
    "\n",
    "# Create the ClientApp\n",
    "client = ClientApp(client_fn=client_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definir el Servidor\n",
    "Del mismo modo que hemos definido un nodo cliente, necesitamos un nodo servidor, que sea el que envíe los pesos del modelo, los reciba actualizados y haga la función  de merging o agregación de los mismos.  * ¿Como se realiza?: Aquí debemos tener un concepto de Flower llamado la estrategia, que define los parametros del entrenamiento distribuido: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FedAvg strategy\n",
    "strategy = FedAvg(\n",
    "    fraction_fit=1.0,  # Sample 100% of available clients for training\n",
    "    fraction_evaluate=0.5,  # Sample 50% of available clients for evaluation\n",
    "    min_fit_clients=10,  # Never sample less than 10 clients for training\n",
    "    min_evaluate_clients=5,  # Never sample less than 5 clients for evaluation\n",
    "    min_available_clients=10,  # Wait until all 10 clients are available\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se observa, la estrategia define varios parametros de simulación distribuida:\n",
    "* **fraction_fit**: Muestrear a todos los nodos de la federación\n",
    "* **fraction_evaluate** : Realizar la evaluación del modelo (métricas) con el 50 por ciento de los nodos.\n",
    "*  **min_fit_clients** : El número mínimo de clientes necesarios para hacer el entrenamiento. \n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del mismo modo que creamos una aplicación para los clientes, es necesario crear una aplicación para el servidor. Esto permite reutilizar código y eventualmente, usar múltiples estrategias en el mismo servidor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def server_fn(context: Context) -> ServerAppComponents:\n",
    "    \"\"\"Construct components that set the ServerApp behaviour.\n",
    "\n",
    "    You can use the settings in `context.run_config` to parameterize the\n",
    "    construction of all elements (e.g the strategy or the number of rounds)\n",
    "    wrapped in the returned ServerAppComponents object.\n",
    "    \"\"\"\n",
    "\n",
    "    # Configure the server for 5 rounds of training\n",
    "    config = ServerConfig(num_rounds=5)\n",
    "\n",
    "    return ServerAppComponents(strategy=strategy, config=config)\n",
    "\n",
    "\n",
    "# Create the ServerApp\n",
    "server = ServerApp(server_fn=server_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento distribuido. \n",
    "En la simulación, ( y en entornos de producción) queremos controlar la forma en que  se ejecuta el entrenamiento en un nodo. Esto se puede definir por parametros  de la siguiente manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the resources each of your clients need\n",
    "# By default, each client will be allocated 1x CPU and 0x GPUs\n",
    "backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 0.0}}\n",
    "\n",
    "# When running on GPU, assign an entire GPU for each client\n",
    "if DEVICE.type == \"cuda\":\n",
    "    backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 1.0}}\n",
    "    # Refer to our Flower framework documentation for more details about Flower simulations\n",
    "    # and how to set up the `backend_config`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donde definimos los recursos y la disposición de la ejecución. En nuestro caso, siempre será en cpu. Finalmente realizamos la ejecución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=5, no round_timeout\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n"
     ]
    }
   ],
   "source": [
    "# Run simulation\n",
    "run_simulation(\n",
    "    server_app=server,\n",
    "    client_app=client,\n",
    "    num_supernodes=NUM_CLIENTS,\n",
    "    backend_config=backend_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".FL_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
